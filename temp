To set up Kafka on a Windows machine and implement a producer and consumer with message queueing in Python, follow these steps:

Step 1: Download and Install Kafka

	1.	Download Kafka:
	•	Go to the official Apache Kafka website: Kafka Downloads.
	•	Download the latest Kafka binary (kafka_2.x.x-x.x.x.tgz) for your operating system.
	2.	Extract Kafka:
	•	Extract the tar file to a location of your choice.
	3.	Install Java:
	•	Kafka requires Java, so ensure you have the latest Java version installed.
	•	You can download it from Java Downloads.
	•	After installing Java, set the JAVA_HOME environment variable.
	4.	Start Zookeeper:
	•	Kafka uses Zookeeper for managing brokers. To start Zookeeper, navigate to the Kafka directory and run:

.\bin\windows\zookeeper-server-start.bat .\config\zookeeper.properties


	5.	Start Kafka Server:
	•	Open another terminal window and run:

.\bin\windows\kafka-server-start.bat .\config\server.properties



Step 2: Install Kafka-Python Package

You need the kafka-python package to interact with Kafka through Python. Install it via pip:

pip install kafka-python

Step 3: Create Kafka Topics

Kafka stores messages in topics. You need to create a topic for producers to send messages and consumers to read from.

.\bin\windows\kafka-topics.bat --create --topic test-topic --bootstrap-server localhost:9092 --partitions 1 --replication-factor 1

You can list the created topics with:

.\bin\windows\kafka-topics.bat --list --bootstrap-server localhost:9092

Step 4: Write Python Code for Kafka Producer and Consumer

Here’s the code for a simple Kafka producer and consumer in Python.

Producer (Python Code)

from kafka import KafkaProducer
import json
import time

# Function to produce messages to Kafka topic
def produce_messages():
    producer = KafkaProducer(
        bootstrap_servers=['localhost:9092'],
        value_serializer=lambda x: json.dumps(x).encode('utf-8')  # Serialize data as JSON
    )
    
    for i in range(10):  # Send 10 messages
        message = {'number': i}
        producer.send('test-topic', value=message)
        print(f"Sent message: {message}")
        time.sleep(1)  # Sleep for a second before sending the next message
    
    producer.flush()  # Ensure all messages are sent
    producer.close()

if __name__ == "__main__":
    produce_messages()

Consumer (Python Code)

from kafka import KafkaConsumer
import json

# Function to consume messages from Kafka topic
def consume_messages():
    consumer = KafkaConsumer(
        'test-topic',  # Topic name
        bootstrap_servers=['localhost:9092'],
        auto_offset_reset='earliest',  # Start from the earliest message
        enable_auto_commit=True,  # Commit messages once consumed
        group_id='consumer-group-1',
        value_serializer=lambda x: json.dumps(x).encode('utf-8'),
        value_deserializer=lambda x: json.loads(x.decode('utf-8'))  # Deserialize data from JSON
    )
    
    for message in consumer:
        print(f"Consumed message: {message.value}")

if __name__ == "__main__":
    consume_messages()

Step 5: Run the Producer and Consumer

	1.	Run the Producer:
	•	Open a terminal window and run the producer script. It will send messages to the test-topic.

python producer.py


	2.	Run the Consumer:
	•	Open another terminal window and run the consumer script. It will consume and display the messages from test-topic.

python consumer.py



Step 6: Check Kafka Logs and Topics

	•	You can check the Kafka logs to ensure everything is working as expected. The logs are typically found in the logs/ directory within the Kafka installation folder.






function prepareFilters(filterObj) {
  const filters = [];

  // Use Object.entries to get key-value pairs
  Object.entries(filterObj).forEach(([key, value]) => {
    filters.push(key);    // Push the key
    filters.push(value);  // Push the value
  });

  return filters;
}





This setup should help you run Kafka on a Windows machine and use Python to interact with it as both a producer and a consumer. Let me know if you run into any issues during the setup!